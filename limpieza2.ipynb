{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d419f592",
   "metadata": {},
   "source": [
    "# Descripcion del dataset\n",
    "\n",
    "Para describir un dataset como **\"Cat in the Dat\"**, seguiría estos pasos:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Descripción General del Dataset**\n",
    "El dataset **\"Cat in the Dat\"** es un conjunto de datos categóricos diseñado para un problema de clasificación binaria. El objetivo es predecir una **variable objetivo binaria (`target`)** basada en múltiples características categóricas. Este dataset es útil para explorar técnicas de preprocesamiento y codificación de datos categóricos.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Objetivo del Dataset**\n",
    "El objetivo principal es construir un modelo que prediga el valor de la variable `target` (0 o 1) utilizando las características categóricas proporcionadas. Este problema es típico en tareas de clasificación supervisada.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Atributos del Dataset**\n",
    "El dataset contiene las siguientes columnas:\n",
    "\n",
    "- **`id`**: Identificador único para cada fila. No tiene relevancia para el análisis.\n",
    "- **`target`**: Variable objetivo binaria (0 o 1). Es el atributo clase que queremos predecir.\n",
    "- **Características categóricas**:\n",
    "  - **Ordinales**: Variables categóricas con un orden lógico (por ejemplo, niveles educativos).\n",
    "  - **Nominales**: Variables categóricas sin un orden lógico (por ejemplo, colores o nombres).\n",
    "  - **Cíclicas**: Variables categóricas que tienen un patrón cíclico (por ejemplo, meses o días de la semana).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Significado de los Atributos**\n",
    "El significado exacto de las columnas puede variar dependiendo de la descripción oficial del dataset (si está disponible). Sin embargo, en general, las columnas categóricas representan diferentes tipos de datos categóricos que deben ser preprocesados antes de usarse en un modelo.\n",
    "\n",
    "Ejemplo de atributos categóricos:\n",
    "- **`bin_0`, `bin_1`, ...`bin_n`**: Variables binarias (0 o 1).\n",
    "- **`nom_0`, `nom_1`, ...`nom_n`**: Variables nominales con múltiples categorías.\n",
    "- **`ord_0`, `ord_1`, ...`ord_n`**: Variables ordinales con un orden lógico.\n",
    "- **`day`, `month`**: Variables cíclicas que representan días y meses.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Atributo Clase**\n",
    "El atributo clase es **`target`**, que toma valores binarios:\n",
    "- **0**: Clase negativa.\n",
    "- **1**: Clase positiva.\n",
    "\n",
    "Este es el atributo que queremos predecir utilizando las demás columnas como características.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Exploración Inicial**\n",
    "Para entender mejor el dataset, realizaría un análisis exploratorio inicial:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Información general del dataset\n",
    "print(df.info())\n",
    "\n",
    "# Resumen estadístico\n",
    "print(df.describe(include=\"all\"))\n",
    "\n",
    "# Verificar valores únicos por columna\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()} valores únicos\")\n",
    "\n",
    "# Visualizar las primeras filas\n",
    "print(df.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Conclusión**\n",
    "El dataset **\"Cat in the Dat\"** es un excelente ejemplo para trabajar con datos categóricos. Su objetivo es predecir una variable binaria (`target`) utilizando una variedad de características categóricas que requieren diferentes técnicas de preprocesamiento, como codificación y manejo de valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341a2ba",
   "metadata": {},
   "source": [
    "# Importacion del dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e74569e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb1140",
   "metadata": {},
   "source": [
    "## Limpieza inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc497f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\3116093107.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id       0\n",
      "bin_0    0\n",
      "bin_1    0\n",
      "bin_2    0\n",
      "bin_3    0\n",
      "bin_4    0\n",
      "nom_0    0\n",
      "nom_1    0\n",
      "nom_2    0\n",
      "nom_3    0\n",
      "nom_4    0\n",
      "nom_5    0\n",
      "nom_6    0\n",
      "nom_7    0\n",
      "nom_8    0\n",
      "nom_9    0\n",
      "ord_0    0\n",
      "ord_1    0\n",
      "ord_2    0\n",
      "ord_3    0\n",
      "ord_4    0\n",
      "ord_5    0\n",
      "day      0\n",
      "month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Llenado de datos faltantes de tipo float64 con la mediana\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "#Llenado de datos faltantes de tipo str con la moda\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "#Datos faltantes\n",
    "datos_faltantes =df.isnull().sum()\n",
    "print(datos_faltantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194601d",
   "metadata": {},
   "source": [
    "## Codificicacion Nominal (One-Hot Encoding) - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae90c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación One-Hot para variables nominales:\n",
      "   nom_0_Blue  nom_0_Green  nom_0_Red  nom_1_Circle  nom_1_Polygon  \\\n",
      "0         1.0          0.0        0.0           0.0            1.0   \n",
      "1         0.0          0.0        1.0           1.0            0.0   \n",
      "2         1.0          0.0        0.0           1.0            0.0   \n",
      "3         0.0          0.0        1.0           0.0            1.0   \n",
      "4         0.0          0.0        1.0           1.0            0.0   \n",
      "\n",
      "   nom_1_Square  nom_1_Star  nom_1_Trapezoid  nom_1_Triangle  nom_2_Axolotl  \\\n",
      "0           0.0         0.0              0.0             0.0            1.0   \n",
      "1           0.0         0.0              0.0             0.0            0.0   \n",
      "2           0.0         0.0              0.0             0.0            1.0   \n",
      "3           0.0         0.0              0.0             0.0            1.0   \n",
      "4           0.0         0.0              0.0             0.0            0.0   \n",
      "\n",
      "   ...  nom_9_fe7e11d45  nom_9_fe7fa8831  nom_9_fe9bdeef3  nom_9_fecb6bcc3  \\\n",
      "0  ...              0.0              0.0              0.0              0.0   \n",
      "1  ...              0.0              0.0              0.0              0.0   \n",
      "2  ...              0.0              0.0              0.0              0.0   \n",
      "3  ...              0.0              0.0              0.0              0.0   \n",
      "4  ...              0.0              0.0              0.0              0.0   \n",
      "\n",
      "   nom_9_fee724acc  nom_9_ff1288133  nom_9_ff12eee03  nom_9_ff412d38f  \\\n",
      "0              0.0              0.0              0.0              0.0   \n",
      "1              0.0              0.0              0.0              0.0   \n",
      "2              0.0              0.0              0.0              0.0   \n",
      "3              0.0              0.0              0.0              0.0   \n",
      "4              0.0              0.0              0.0              0.0   \n",
      "\n",
      "   nom_9_ff4a11902  nom_9_ff4a11ad3  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n",
      "\n",
      "[5 rows x 5421 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Seleccionar columnas nominales\n",
    "columnas_nominales = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']  \n",
    "\n",
    "# Aplicar One-Hot Encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_nominal_encoded = encoder.fit_transform(df[columnas_nominales])\n",
    "\n",
    "# Crear un DataFrame con los nombres de las columnas codificadas\n",
    "feature_names = encoder.get_feature_names_out(columnas_nominales)\n",
    "X_nominal_encoded_df = pd.DataFrame(X_nominal_encoded, columns=feature_names)\n",
    "\n",
    "print(\"\\nCodificación One-Hot para variables nominales:\")\n",
    "print(X_nominal_encoded_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33c0eba",
   "metadata": {},
   "source": [
    "## Codificacion Ordinal (Ordinal Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4386c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Codificación Ordinal para variables ordinales:\n",
      "   ord_0  ord_1  ord_2  ord_3  ord_4  ord_5\n",
      "0    2.0    4.0    0.0    5.0   20.0  146.0\n",
      "1    0.0    4.0    1.0   13.0   13.0   21.0\n",
      "2    0.0    1.0    5.0    8.0   13.0   12.0\n",
      "3    0.0    1.0    3.0   12.0    1.0    0.0\n",
      "4    0.0    0.0    4.0   14.0    9.0   14.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Seleccionar columnas ordinales\n",
    "columnas_ordinales = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']  \n",
    "# Definir el orden lógico de las categorías (si aplica)\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()  # Sin especificar categorías\n",
    "X_ordinal_encoded = ordinal_encoder.fit_transform(df[columnas_ordinales])\n",
    "\n",
    "# Crear un DataFrame con las columnas codificadas\n",
    "X_ordinal_encoded_df = pd.DataFrame(X_ordinal_encoded, columns=columnas_ordinales)\n",
    "\n",
    "print(\"\\nCodificación Ordinal para variables ordinales:\")\n",
    "print(X_ordinal_encoded_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba62d1",
   "metadata": {},
   "source": [
    "## Codificacion de variables ciclicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5550e959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformación cíclica para variables 'day' y 'month':\n",
      "    day_sin   day_cos     month_sin     month_cos\n",
      "0  0.433884 -0.900969 -1.000000e+00 -1.836970e-16\n",
      "1  0.974928 -0.222521 -8.660254e-01 -5.000000e-01\n",
      "2  0.974928 -0.222521  1.224647e-16 -1.000000e+00\n",
      "3  0.781831  0.623490  1.224647e-16 -1.000000e+00\n",
      "4  0.433884 -0.900969  1.000000e+00  6.123234e-17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Transformar variables cíclicas\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['day'] / 7)  # Día de la semana (7 días)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['day'] / 7)\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)  # Mes del año (12 meses)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "print(\"\\nTransformación cíclica para variables 'day' y 'month':\")\n",
    "print(df[['day_sin', 'day_cos', 'month_sin', 'month_cos']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b873efd",
   "metadata": {},
   "source": [
    "## Combinar las transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33b3c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset final después de las transformaciones:\n",
      "   nom_0_Blue  nom_0_Green  nom_0_Red  nom_1_Circle  nom_1_Polygon  \\\n",
      "0         1.0          0.0        0.0           0.0            1.0   \n",
      "1         0.0          0.0        1.0           1.0            0.0   \n",
      "2         1.0          0.0        0.0           1.0            0.0   \n",
      "3         0.0          0.0        1.0           0.0            1.0   \n",
      "4         0.0          0.0        1.0           1.0            0.0   \n",
      "\n",
      "   nom_1_Square  nom_1_Star  nom_1_Trapezoid  nom_1_Triangle  nom_2_Axolotl  \\\n",
      "0           0.0         0.0              0.0             0.0            1.0   \n",
      "1           0.0         0.0              0.0             0.0            0.0   \n",
      "2           0.0         0.0              0.0             0.0            1.0   \n",
      "3           0.0         0.0              0.0             0.0            1.0   \n",
      "4           0.0         0.0              0.0             0.0            0.0   \n",
      "\n",
      "   ...  ord_0  ord_1  ord_2  ord_3  ord_4  ord_5   day_sin   day_cos  \\\n",
      "0  ...    2.0    4.0    0.0    5.0   20.0  146.0  0.433884 -0.900969   \n",
      "1  ...    0.0    4.0    1.0   13.0   13.0   21.0  0.974928 -0.222521   \n",
      "2  ...    0.0    1.0    5.0    8.0   13.0   12.0  0.974928 -0.222521   \n",
      "3  ...    0.0    1.0    3.0   12.0    1.0    0.0  0.781831  0.623490   \n",
      "4  ...    0.0    0.0    4.0   14.0    9.0   14.0  0.433884 -0.900969   \n",
      "\n",
      "      month_sin     month_cos  \n",
      "0 -1.000000e+00 -1.836970e-16  \n",
      "1 -8.660254e-01 -5.000000e-01  \n",
      "2  1.224647e-16 -1.000000e+00  \n",
      "3  1.224647e-16 -1.000000e+00  \n",
      "4  1.000000e+00  6.123234e-17  \n",
      "\n",
      "[5 rows x 5431 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinar todas las transformaciones\n",
    "df_final = pd.concat([X_nominal_encoded_df, X_ordinal_encoded_df, df[['day_sin', 'day_cos', 'month_sin', 'month_cos']]], axis=1)\n",
    "\n",
    "print(\"\\nDataset final después de las transformaciones:\")\n",
    "print(df_final.head())\n",
    "type(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776fb2ee",
   "metadata": {},
   "source": [
    "# Limpieza y codificacion del dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0616e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df_train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_13260\\2253387252.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train[col].fillna(df_train[col].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "bin_0     0\n",
      "bin_1     0\n",
      "bin_2     0\n",
      "bin_3     0\n",
      "bin_4     0\n",
      "nom_0     0\n",
      "nom_1     0\n",
      "nom_2     0\n",
      "nom_3     0\n",
      "nom_4     0\n",
      "nom_5     0\n",
      "nom_6     0\n",
      "nom_7     0\n",
      "nom_8     0\n",
      "nom_9     0\n",
      "ord_0     0\n",
      "ord_1     0\n",
      "ord_2     0\n",
      "ord_3     0\n",
      "ord_4     0\n",
      "ord_5     0\n",
      "day       0\n",
      "month     0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Llenado de datos faltantes de tipo float64 con la mediana\n",
    "for col in df_train.select_dtypes(include=['float64']).columns:\n",
    "    df_train[col].fillna(df_train[col].median(), inplace=True)\n",
    "\n",
    "#Llenado de datos faltantes de tipo str con la moda\n",
    "for col in df_train.select_dtypes(include=['object']).columns:\n",
    "    df_train[col].fillna(df_train[col].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "#Datos faltantes\n",
    "datos_faltantes_train = df_train.isnull().sum()\n",
    "print(datos_faltantes_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ad321",
   "metadata": {},
   "source": [
    "## Codificacion Nominal One Hot Encooding (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e88134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4206454c",
   "metadata": {},
   "source": [
    "## Clasificacion con arboles de decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8cbbb",
   "metadata": {},
   "source": [
    "## Carga de datos train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3740a342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar datos test \n",
    "test = pd.read_csv('train.csv')\n",
    "X = test.drop(columns=['target'], axis=1)\n",
    "y = test['target']\n",
    "type(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c1fc78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "599995    0\n",
      "599996    0\n",
      "599997    0\n",
      "599998    0\n",
      "599999    0\n",
      "Name: target, Length: 600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dividir en entrenamiento y prueba\n",
    "X_train = X \n",
    "X_test = df_final.to_numpy\n",
    "y_train = y \n",
    "y_test = y \n",
    "print(y_train)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id  bin_0  bin_1  bin_2 bin_3 bin_4 nom_0      nom_1    nom_2  \\\n",
      "0            0    0.0    0.0    0.0     F     N   Red  Trapezoid  Hamster   \n",
      "1            1    1.0    1.0    0.0     F     Y   Red       Star  Axolotl   \n",
      "2            2    0.0    1.0    0.0     F     N   Red        NaN  Hamster   \n",
      "3            3    NaN    0.0    0.0     F     N   Red     Circle  Hamster   \n",
      "4            4    0.0    NaN    0.0     T     N   Red   Triangle  Hamster   \n",
      "...        ...    ...    ...    ...   ...   ...   ...        ...      ...   \n",
      "599995  599995    0.0    1.0    0.0     T     N   Red    Polygon  Axolotl   \n",
      "599996  599996    1.0    0.0    0.0     T     Y  Blue    Polygon      Dog   \n",
      "599997  599997    0.0    0.0    0.0     F     Y   Red     Circle  Axolotl   \n",
      "599998  599998    1.0    1.0    0.0     F     Y   NaN    Polygon  Axolotl   \n",
      "599999  599999    0.0    0.0    0.0     T     N  Blue   Triangle      Dog   \n",
      "\n",
      "             nom_3  ...      nom_8      nom_9 ord_0        ord_1        ord_2  \\\n",
      "0           Russia  ...  0256c7a4b  02e7c8990   3.0  Contributor          Hot   \n",
      "1              NaN  ...  52ead350c  f37df64af   3.0  Grandmaster         Warm   \n",
      "2           Canada  ...  745b909d1        NaN   3.0          NaN     Freezing   \n",
      "3          Finland  ...  bdaa56dd1  f9d456e57   1.0       Novice     Lava Hot   \n",
      "4       Costa Rica  ...        NaN  c5361037c   3.0  Grandmaster         Cold   \n",
      "...            ...  ...        ...        ...   ...          ...          ...   \n",
      "599995       India  ...  158183c63  015c63324   3.0       Novice     Freezing   \n",
      "599996  Costa Rica  ...  e9fde8fa8  a02ae6a63   2.0       Novice  Boiling Hot   \n",
      "599997      Russia  ...  cccbca824  40f9610c1   2.0  Contributor     Freezing   \n",
      "599998         NaN  ...  4164322bd  c1a8374a0   1.0       Master         Warm   \n",
      "599999      Russia  ...        NaN  e2aea7784   1.0  Contributor  Boiling Hot   \n",
      "\n",
      "       ord_3  ord_4 ord_5  day month  \n",
      "0          c      U    Pw  6.0   3.0  \n",
      "1          e      X    pE  7.0   7.0  \n",
      "2          n      P    eN  5.0   9.0  \n",
      "3          a      C   NaN  3.0   3.0  \n",
      "4          h      C    OZ  5.0  12.0  \n",
      "...      ...    ...   ...  ...   ...  \n",
      "599995     a      R    GZ  5.0   NaN  \n",
      "599996     n      N    sf  NaN   3.0  \n",
      "599997     n      H    MV  7.0   5.0  \n",
      "599998     m      X    Ey  1.0   5.0  \n",
      "599999     b      O    uI  5.0   8.0  \n",
      "\n",
      "[600000 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# ===== Modelo: Árbol de decisión =====\n",
    "arbol = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "arbol.fit(X_train, y_train)\n",
    "y_pred_arbol = arbol.predict(X_test)\n",
    "acc_arbol = accuracy_score(y_test, y_pred_arbol)\n",
    "print(f\"Precisión Árbol de decisión: {acc_arbol:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ee310",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [400000, 150]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m X \u001b[38;5;241m=\u001b[39m test\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Dividir en entrenamiento y prueba\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ===== Modelo: Árbol de decisión =====\u001b[39;00m\n\u001b[0;32m     22\u001b[0m arbol \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2848\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2852\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2853\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [400000, 150]"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar dataset Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# ===== Modelo: Árbol de decisión =====\n",
    "arbol = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "arbol.fit(X_train, y_train)\n",
    "y_pred_arbol = arbol.predict(X_test)\n",
    "acc_arbol = accuracy_score(y_test, y_pred_arbol)\n",
    "print(f\"Precisión Árbol de decisión: {acc_arbol:.2f}\")\n",
    "\n",
    "#Agregar aqui el codigo hecho en clase\n",
    "\n",
    "# Visualizar el árbol\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(arbol, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.title(\"Árbol de decisión - Iris\")\n",
    "plt.show()\n",
    "\n",
    "# ===== Modelo: K-Nearest Neighbors =====\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"Precisión KNN: {acc_knn:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
